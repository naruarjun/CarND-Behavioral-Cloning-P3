{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior.\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images.\n",
    "* Train and validate the model with a training and validation set.\n",
    "* Test that the model successfully drives around track one without leaving the road.\n",
    "* Summarize the results with a written report.\n",
    "\n",
    "[//]: # (Image References)\n",
    "[image1]: ./photos_report/shadow.png\n",
    "[image2]: ./photos_report/flip.png \n",
    "\n",
    "\n",
    "# **Rubric Points**\n",
    "# Here I will consider the rubric points individually and describe how I addressed each point in my implementation.\n",
    "\n",
    "## Files Submitted & Code Quality\n",
    "### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "\n",
    "    model.py containing the script to create and train the model\n",
    "    drive.py for driving the car in autonomous mode\n",
    "    model.h5 containing a trained convolution neural network\n",
    "    writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "### 2. Submission includes functional code\n",
    "\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "\n",
    "python3 drive.py model.h5\n",
    "\n",
    "### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works.\n",
    "\n",
    "## Model Architecture and Training Strategy\n",
    "### 1. An appropriate model architecture has been employed\n",
    "\n",
    "A convolution Neurral network with a flatten neural network with one output node was used to train the model. The data was first Normalized and mean centered so that any features that were biased in the data do not affect the learning too much. The image was then cropped to only look at the road and remove the part of the image that looks at the trees and the sky.  \n",
    "\n",
    "The CNN is made up of 4 Convolution Layers with Relu Activation and Max Pooling at every stage. The filter size for the first two layers is 5X5 and the filter size for the last two layers is 3X3. The depth begins at 1(the input is grayscaled) for the image and then is increased to 6 then 18 then 36 and finally 48 by the final layer.\n",
    "\n",
    "A dropout layer was added after the final convolution layer to ensure we do not overfit tot he data. I had initially added dropouts to every layer and was running into significant issues with learning the features and thus kept decreasing the number of dropout layers until this configuration gave me the desired result.\n",
    "\n",
    "After this we have a flat Neural network going from 512->256->128->32->1 nodes. The output of this is the steering angle of the car.\n",
    "### 2. Attempts to reduce overfitting in the model\n",
    "\n",
    "The model contains dropout layers in order to reduce overfitting which are explained above. The model was  then tested on track 1 and it drove perfectly. Data augmentation also helped it as it stopped hugging the right lane and lead to much better results\n",
    "### 3. Model parameter tuning\n",
    "\n",
    "The model used an adam optimizer. No further tuning of learning rate was done as optimal results were observed at the default learning rate. Parameters such as number of layers and filter size were increemntally increased until optimal results were observed.\n",
    "### 4. Appropriate training data\n",
    "\n",
    "Training data was chosen to keep the vehicle driving in the middle the road. This was done via collection of data in both directions and also the collection of recovery data, that is allowing the car to drift off the center and then recentering it. Details can be found below.\n",
    "\n",
    "\n",
    "### DATA COLLECTION:-\n",
    "\n",
    "The different data files that were collected are as follows:\n",
    "1. Anticlockwise on Track\n",
    "2. Clockwise on Track\n",
    "\n",
    "Both the data files was collected at a average speed of 29.\n",
    "\n",
    "Both sets of files also contain the recovery data. So I went to the edge of the road and turned swiftly back multiple times to get the recovery data.\n",
    "\n",
    "### DATA AUGMENTATION:-\n",
    "\n",
    "3 types of augmentation was done:\n",
    "1. Flipping the images(making mirror images)\n",
    "2. Shadow Augmnentation\n",
    "\n",
    "Fliping of images is done so that the model is not biased towards one direction by the data\n",
    "\n",
    "![Flipping visualization][image2]\n",
    "\n",
    "Shadow augmentation was done to make the model robust to shadows. It is done taking two random points on the boundary of the image and decreasing the brightness of left or right side which is also chosen randomly.\n",
    "\n",
    "![Shadow augmentation][image1]\n",
    "\n",
    "### BASIC PIPELINE\n",
    "\n",
    "So first the image is grayscaled. The car is driven using only the center camera. Thus I made the assumption that if the center camera saw what the left camera saw then we are veering to the left and thus need to make a motion to the right to come back to the center of the lane.\n",
    "\n",
    "Similarly if the image seen in the right camera is seen in the center camera then the car is too far right and should veer left. Thus the data was changed to account for this. This tripled the number of data points we have.\n",
    "\n",
    "Thus correction added\n",
    "\n",
    "1. Right image = Turn left by 0.2 Deg (Arbitrary Value)\n",
    "2. Left Image = turn right by 0.2 Deg\n",
    "3. Center Image - No Correction\n",
    "\n",
    "Then the shadow and flipping augmentation is applied. Once the augmentation is done we normalize the data and center its mean. Then we crop the image to remove the part of the car that is visible and the scenery. Then the image is passed through the convolutional network.\n",
    "\n",
    "I started with the smallest network possible and then incrementally added layers. Overfitting was a m,ajor problem so I did add dropout. It stopped hugging the right lane. Clockwise data also helped resolve this problem. the network was very big, so I grayscaled the images to make the dataset and initial layer of network smaller. Since results were comparable to the coloured network, I kept it this way.\n",
    "\n",
    "\n",
    "The simulator was run on screen resolution - 1024x768 and graphics quality - good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
